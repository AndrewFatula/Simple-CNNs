{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrewFatula/Simple-CNNs/blob/master/mnist_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWc-aSeyKb4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import models \n",
        "from keras import layers\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as k_backend\n",
        "from keras.datasets import mnist\n",
        "from keras import regularizers\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "tf.enable_eager_execution()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4kIaNc4LT4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0], 1, 28, 28)\n",
        "x_test = x_test.reshape(x_test.shape[0], 1, 28, 28)\n",
        "\n",
        "x_train = x_train.astype(\"float32\")\n",
        "x_test = x_test.astype(\"float32\")\n",
        "\n",
        "x_train = (x_train - np.mean(x_train))/ x_train.std()\n",
        "x_test = (x_test - np.mean(x_test))/ x_test.std()\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "batch_size = 512\n",
        "num_classes = 10\n",
        "n_filters = 64\n",
        "n_fc1 = 512\n",
        "n_fc2 = 128\n",
        "pool = (4,4)\n",
        "kernel_size1 = (5,5)\n",
        "kernel_size2 = (4,4)\n",
        "kernel_size3 = (2,2)\n",
        "input_shape1 = (1, 28, 28)\n",
        "input_shape2 = (n_filters, 23, 23)\n",
        "input_shape3 = (n_filters, 11, 11)\n",
        "n_epochs = 40\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMnpdsbErIEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_net = tf.keras.Sequential([\n",
        "tf.keras.layers.Conv2D(n_filters, kernel_size1, input_shape=input_shape1, data_format=\"channels_first\", activation=\"relu\", kernel_regularizer=regularizers.l2(0.002)),\n",
        "tf.keras.layers.Dropout(0.3),\n",
        "tf.keras.layers.MaxPooling2D(pool_size = pool, strides = (2,2), data_format=\"channels_first\"),\n",
        "tf.keras.layers.Conv2D(n_filters*2, kernel_size3, input_shape=input_shape3, data_format=\"channels_first\", activation=\"relu\", kernel_regularizer=regularizers.l2(0.002)),\n",
        "tf.keras.layers.Dropout(0.2),\n",
        "tf.keras.layers.MaxPooling2D(pool_size = (2,2), data_format=\"channels_first\"),\n",
        "tf.keras.layers.Flatten(data_format=\"channels_first\"),\n",
        "tf.keras.layers.Dense(n_fc1, activation=\"sigmoid\", kernel_regularizer=regularizers.l2(0.002)),\n",
        "tf.keras.layers.Dropout(0.2),\n",
        "tf.keras.layers.Dense(n_fc2, activation=\"sigmoid\", kernel_regularizer=regularizers.l2(0.002)),\n",
        "tf.keras.layers.Dropout(0.1),\n",
        "tf.keras.layers.Dense(num_classes, kernel_regularizer=regularizers.l2(0.002))\n",
        "])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou1_03xmpQ7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB915qHHQgJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test_split(x, y):\n",
        "  data = list(zip(x,y))\n",
        "  np.random.shuffle(data)\n",
        "  train_data = data[0:50000]\n",
        "  test_data = data[50000:]\n",
        "  return zip(*train_data), zip(*test_data)\n",
        "\n",
        "def get_batches(x, y, batch_size):\n",
        "  length = np.shape(x)[0]\n",
        "  n_of_entries = int(length/batch_size)\n",
        "  batched_x = []\n",
        "  batched_y = []\n",
        "\n",
        "  for i in range(n_of_entries):\n",
        "    batch_x = []\n",
        "    batch_y = []\n",
        "    for j in range(batch_size):\n",
        "      batch_x.append(x[i*batch_size + j])\n",
        "      batch_y.append(y[i*batch_size + j])\n",
        "\n",
        "    batched_x.append(batch_x)\n",
        "    batched_y.append(batch_y)\n",
        "\n",
        "  return batched_x, batched_y     \n",
        "\n",
        "def get_accuracy(labels, images, model):\n",
        "  length = len(labels)\n",
        "  step_length = 1000\n",
        "  total_correct = 0\n",
        "  images = np.expand_dims(images, 1)\n",
        "  for i in range(step_length):\n",
        "    step_labels = labels[i*step_length : (i+1)*step_length]\n",
        "    step_logits = model(images[step_length*i : step_length*(1+i)])\n",
        "    pred_numbers = np.argmax(step_logits, axis = 1)\n",
        "    total_correct += np.sum(np.where(step_labels == pred_numbers,1,0))\n",
        "  return total_correct/length\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = train_test_split(mnist_images, mnist_labels)\n",
        "\n",
        "train_images = np.float32(np.array(train_images)/255.0)\n",
        "test_images = np.float32(np.array(test_images)/255.0)\n",
        "\n",
        "test_labels = np.array(test_labels)\n",
        "test_images = np.array(test_images)\n",
        "\n",
        "\n",
        "\n",
        "train_batched_images, train_batched_labels = get_batches(train_images, train_labels, batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shdfCiVncjUg",
        "colab_type": "code",
        "outputId": "8653c780-c91b-4374-adb7-7218ca51a783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "\n",
        "start = time.localtime(time.time())\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(0.0005)\n",
        "\n",
        "for i in range(n_epochs):\n",
        "  train_batches = list(zip(train_batched_images, train_batched_labels))\n",
        "  np.random.shuffle(train_batches)\n",
        "  for batch_x, batch_y in train_batches:\n",
        "    batch_x = np.expand_dims(batch_x, axis = 1)\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = mnist_net(batch_x, training=True)\n",
        "    \n",
        "      loss_value = tf.losses.sparse_softmax_cross_entropy(batch_y, logits)\n",
        "      grads = tape.gradient(loss_value, mnist_net.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, mnist_net.trainable_variables),\n",
        "                              global_step=tf.train.get_or_create_global_step())\n",
        "  \n",
        "  \n",
        "  print(get_accuracy(test_labels, test_images, mnist_net))\n",
        "\n",
        "end = time.localtime(time.time())\n",
        "start_in_sec = start[3]*3600 + start[4]*60 + start[5]\n",
        "end_in_sec = end[3]*3600 + end[4]*60 + end[5]\n",
        "\n",
        "\n",
        "all_time_min = int((end_in_sec-start_in_sec)/60)\n",
        "all_time_sec = (end_in_sec-start_in_sec)%60\n",
        "if all_time_min < 10:\n",
        "\tif all_time_sec < 10:\n",
        "\t\tprint('0%s:0%s' % (all_time_min, all_time_sec ))\n",
        "\telse:\n",
        "\t\tprint('0%s:%s' % (all_time_min, all_time_sec ))\t\n",
        "else:\n",
        "\tif all_time_sec < 10:\n",
        "\t\tprint('%s:0%s' % (all_time_min, all_time_sec ))\n",
        "\telse:\n",
        "\t\tprint('%s:%s' % (all_time_min, all_time_sec ))\t\n",
        "\t\t\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.944\n",
            "0.968\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}